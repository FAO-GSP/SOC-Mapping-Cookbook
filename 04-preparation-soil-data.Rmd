# Preparation of local soil data {#preparation}
*G.F. Olmedo & R. Baritz*

The authors of this Chapter used **R** packages. To run the code provided in this Chapter, the following packages need to be installed in the **R** user library. If the packages are not yet installed, the `install.packages()` function can be used.

```{r, eval=FALSE}
# Installing packages for Chapter 'Preparation of Local Soil Data'
install.packages(c("aqp", "GSIF"))
```

## Soil profiles and soil augers

Soil profiles are complex real-world entities. They are composed of soil layers which form soil horizons; the soil layers have different properties and these properties are evaluated with different methods.  As we know, soil and vertical soil properties are landscape elements and part of matter dynamics (water, nutrients, gases, habitat, etc.). Local soil samples or soil profiles add a third dimension into the spatial assessment of soil properties in the landscape. 

Most commonly, soils are described as vertical profiles using soil pits (sometimes also augerings, but this is less accurate). Soil profiles are described using macro-morphological properties. These properties can be assessed in the field without analysis by making a field inventory or land evaluation. For additional quantitative analysis, soils are then sampled by genetic horizons or by depth class. 

The sampling of soils is the basis to obtain quantitative information. Depending on the goal of a project, sampling can be quite diverse. Sampling can follow the description of the soil or can be conducted without, for example using a spade or auger to generate a composite sample for a certain depth independent of the morphological features such as soil horizons. 
Sampling locations can be representative of a certain location, project, field, or mapped object, such as a soil type. 

## Soil database

### Type of soil database

In order to process and evaluate soil information from field assessments, soil profile data and analytical information need to be stored in a database. This can be a set of simple Microsoft Office *Excel* spreadsheets, or a relational or object-oriented database management system [@baritz2008environmental]. When working in **R**, `SoilProfileCollections` (SPC) from the **R** **aqp** package are a useful tool. Tables \@ref(tab:site-level) and \@ref(tab:horizon-level) are examples of how soil information can be stored. The advantage of such organization is the possibility to develop relational databases which can be easily queried. Such a systematic approach will support the organization of national soil information and will reduce errors in future modeling exercises [@baritz2008environmental].

Table \@ref(tab:site-level) stores site-level data, which describe the location of the soil description and/or sampling site: spatial coordinates, landscape attributes such as slope gradient and slope form, soil class, land cover type, rock type, etc. In this table, every row should hold a single soil profile. One column, usually the first one, should be the soil profile’s unique identifier. Using the latter, soil information can be easily linked from one table to another.

```{r site-level, echo=F}
dat <- read.csv("examples/site-ex.csv")
knitr::kable(dat, caption = "Example for site-level data table", booktabs = TRUE)
```

Table \@ref(tab:horizon-level) stores information from the soil description, such as horizon name, horizon thickness, organic matter content, carbonate content, soil color, laboratory soil analysis, etc. The first column contains the soil profile’s unique identifier. It is important to include the upper and lower limits for each soil layer; in case the sampling strategy deviates from soil layers/soil horizons, the upper and lower depth of the sampling locations should be specified if possible. This information is needed for modeling soil properties over the soil profile.


```{r horizon-level, echo=FALSE}
dat <- read.csv("examples/horizons-ex.csv")
knitr::kable(dat, caption = "Example for profile-description table", booktabs = TRUE)
```

### Technical steps – Loading soil data from tables in R

This Chapter includes two examples for soil data preparation. As each step for the soil data preparation is explained in detail, the given code is mixed with text. A copy of the bare code is presented in Section \@ref(cd:PreparationProfiles) for using soil profiles data, and for using topsoil or auger data the code can be found in Section \@ref(cd:PreparationAuger).

The following code shows the necessary steps for loading 
soil profiles data.

**Step 1 - Loading soil horizons data**

```{r, results='hold'}
dat <- read.csv(file = "data/horizons.csv")

# Explore the data
str(dat)
summary(dat)
```

**Step 2 - Loading site-level data**

```{r}
dat_sites <- read.csv(file = "data/site-level.csv")

# Explore the data
str(dat_sites)
```


## Completeness of measurements and estimates

The [*GSP Guidelines for Sharing National Data/Information to Compile a Global Soil Organic Carbon (GSOC) Map*](http://www.fao.org/3/a-bp164e.pdf) [@gsp_guidelines_2017] specify which soil parameters are needed to produce a GSOCmap. Of course, other soil properties can be evaluated and modeled using this cookbook as well.

SOC stocks for soil horizons or targeted soil depths can be calculated using the equations in Section 8.4.3 of the [*GSP Guidelines for Sharing National Data/Information to Compile a Global Soil Organic Carbon (GSOC) Map*](http://www.fao.org/3/a-bp164e.pdf). Carbon concentration, bulk density and stone content for a certain depth or genetic horizon are needed to calculate the amount of carbon stored in that depth interval/soil horizon. In many countries, legacy data from former surveys and projects, as well as from various owners and data sources are compiled. Often, measured bulk densities are either missing, only available for few soil profiles, or are estimated. Stones in the soil profile are usually only estimated, and if augers are used for sampling, stone content is not assessed at all. Pedo-transfer functions (PTFs) can be used to fill data gaps (e.g. bulk density), and interpolation approaches can be used to infer from measured depths to target depths. 

### Stones

The estimation of stoniness is difficult and time-consuming, and therefore not carried out in many national soil inventories, or only estimated visually in the profile. Unfortunately, if soil inventories and sampling are done with simple pits or augers rather than standard soil pits, stones are very often not assessed. 

As a proxy, it is recommended to derive national default values from well-described soil profile pits by soil type.

```{r, fig.cap="Histogram of coarse fragments values"}
# Summary of column CRF (coarse fragments) in the example data base
summary(dat$CRF)

# Convert NA's to 0
dat$CRF[is.na(dat$CRF)] <- 0

hist(dat$CRF, col = "light gray")
```


### Bulk density

The amount of fine earth is one of the basic estimation parameters to estimate SOC stocks in the mineral soil as well as in peat layers. It depends on the volume of soil considered ($\text{depth} \times \text{reference area}$) and the bulk density (BD). BD expresses the soil weight per unit volume. When determining the BD, it is important to subtract stones, if any, from the cylinder samples; if this is not done, BD is underestimated, and the resulting SOC stocks are overestimated. Stones in the cylinders are added to the total stone content in order to correct for the total amount of fine earth per volume of soil in a given area.

Most of the soil profiles in national databases come from agricultural land. Very often, BD estimates do not consider fine stones because top soils (e.g. plough layers) seem to be free of visible stones.

**Mineral soil**: Default values from the [*General Guide for Estimating Moist Bulk Density*](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/survey/office/ssr10/tr/?cid=nrcs144p2_074844) given by @USDA_2018. If analytical BD is missing, BD can be estimated using pedo-transfer functions (see examples listed below).

For organic soil material, $BD_x$ can be estimated as follows, considering existing litter layers $L$ (or Oi horizon); organic or duff layers, partially decomposed material above the mineral soil and beneath the litter layer; fermentation horizons $F$;humus horizons $H$ (or Oe and Oa horizons); and peat layers $P$, as described in the [*U.S. Soil Taxonomy*](https://www.nrcs.usda.gov/Internet/FSE_DOCUMENTS/nrcs142p2_051232.pdf) [@united1975soil]. 

**Forest floor**: Default values from @barney_forest_1981 and @ottmar_litter_2007:

* Pine: $BD_{L} = 0.018 g \cdot cm^{-3}$; $BD_{F,H} = 0.057 g \cdot cm^{-3}$

* Hardwood: $BD_{L} = 0.012 g \cdot cm^{-3}$

* Birch: $BD_{F,H} = 0.17 g \cdot cm^{-3}$

* Spruce: $BD_{L} = 0.051 g \cdot cm^{-3}$;  $BD_{H}= 0.13 g \cdot cm^{-3}$

**Peat**: The range of peat BD is generally from 0.02 to 0.3$t \cdot m^{-3}$ depending on maturity and compaction, as well as the ash content [@agus_measuring_2011]. total and @agus_measuring_2011 distinguish different peat decomposition types with different C content:

* Sapric: $BD_{P,\text{sapric}} = 0.174 g \cdot cm^{-3}$ ($48.90\%$ C)

* Hemic: $BD_{P,\text{hemic}} = 0.117 g \cdot cm^{-3}$ ($52.27\%$ C)

* Fibric: $BD_{P,\text{fibric}} = 0.089 g \cdot cm^{-3}$ ($53.56\%$ C)

Example equations for PTFs to estimate $BD$, based on the soil organic matter (SOM) ($OM$) content in percent (%):

\cite{saini_1966_organic}:

\begin{equation}
BD = 1.62-0.06 * OM
\end{equation}

\cite{Drew1973}:

\begin{equation}
BD = 1/(0.6268 + 0.0361 * OM)
\end{equation}

\cite{jeffrey1970note}:

\begin{equation}
BD = 1.482 - 0.6786 * (log OM)
\end{equation}

\cite{Grigal1989}:

\begin{equation}
BD = 0.669 + 0.941 * e^{(-0,06 * OM)}
\end{equation}

\cite{adams1973effect}:

\begin{equation}
BD = 100/(OM/0.244 + (100-OM))/MBD
\end{equation}

\cite{honeysett1989use}:

\begin{equation}
BD = 1/(0.564 + 0.0556*OM)
\end{equation}


where $MDB$ is the mineral particle density, assumed to be the specific gravity of quartz, $2.65 Mg \cdot m^{-3}$. And $OM$ is the SOM content, estimated as $OM = SOC \cdot 1.724$, with $SOC$ content in percent (%).

Each method to estimate the BD presented in is derived from a specific set of regional soils that is regionally adapted. Selection of the proper method for a given country shall be based on existing reviews and comparisons. 

```{r}
# Creating a function in R to estimate BLD using the SOC
# SOC is the soil organic carbon content in percent %
estimateBD <- function(SOC, method="Saini1996"){
  OM <- SOC * 1.724
  if(method=="Saini1996"){BD <- 1.62 - 0.06 * OM}
  if(method=="Drew1973"){BD <- 1 / (0.6268 + 0.0361 * OM)}
  if(method=="Jeffrey1979"){BD <- 1.482 - 0.6786 * (log(OM))}
  if(method=="Grigal1989"){BD <- 0.669 + 0.941 * exp(1)^(-0.06 * OM)}
  if(method=="Adams1973"){BD <- 100 / (OM /0.244 + (100 - OM)/2.65)}
  if(method=="Honeyset_Ratkowsky1989"){BD <- 1/(0.564 + 0.0556 * OM)}
  return(BD)
}
```


```{r, fig.cap="Histogram of bulk density values"}
# Summary of BLD (bulk density) in the example data base
summary(dat$BLD)
hist(dat$BLD, col = 'light gray', breaks = 32)
```

Exploring SOC and bulk density values in the database is an important step for ensuring quality of the map. Digital soil mapping framework is a data-driven approach to modelling spatial distribution of soil properties, therefore any irregularities or errors in the input data may significantly influence modelling results. In the current example database  we can observe bulk density values as low as 0 kg/m3 and as high as 2.93 g/cm3. Having 0 g/сm3 bulk density values is physically impossible, and the values higher than 2 g/сm3 are not typical for fine earth \citep{@USDA_2018} and most likely correspond to coarse fragments. The irregularities in the data may occur due to errors in field measurement procedures, wrong unit conversion or simply typing mistakes. In case there is doubt in the quality of the input data, the questionable values should be thoroughly checked and, if found erroneous, removed from the database.

```{r}
# remove bad values
dat$BLD[dat$BLD == 0] <- NA
dat$BLD[dat$BLD > 2] <- NA
summary(dat$BLD)
```



```{r}
# See the summary of values produced using the pedo-transfer 
# function with one of the proposed methods
summary(estimateBD(dat$SOC[is.na(dat$BLD)], 
                   method="Honeyset_Ratkowsky1989"))

# Fill NA's using the pedo-transfer function
dat$BLD[is.na(dat$BLD)] <- estimateBD(dat$SOC[is.na(dat$BLD)], 
                                      method="Honeyset_Ratkowsky1989")

# Explore the results
hist(dat$BLD, col = 'light gray', breaks = 32)
```



### Soil carbon analysis

\cite{rosell2001soil} have closely reviewed the different SOC and SOM estimation procedures, and have also drawn some conclusions about the sources of errors. Determination of SOC from dry combustion methods is least susceptible to errors. 

* **Dry combustion by Loss on Ignition (LOI)**: SOC is re-calculated applying a conversion factor. It is commonly assumed, that organic matter contains an average of 58% organic carbon (so-called Van Bemmelen factor 1.724; for non-organic horizons: $SOC = SOM / 1.724$). For organic horizons, conversion factor ranges from 1.9 to 2.5 \citep{nelson1982total}. The inorganic carbon is not resolved, since typically, temperatures between 400°C and 550°C are used.

* **Wet oxidation**: Since wet oxidation is applied without additional (external) heating, low temperatures of around 120°C (internal heat) are typical. Thus, the oxidation of carbon is incomplete, and a so-called oxidation factor needs to be applied. With external heating, the C-recovery of the method becomes improved, up to complete recovery. No correction of the mineral carbon is needed. Wet oxidation should typically only be applied to samples with <5% organic matter.

Usually, an average of 76% organic carbon is recovered, leading to a standard oxidation factor of 1.33 \citep{lettens2005soil}.

### Carbonates

In case the total organic carbon is determined with temperatures higher than 600°C to 800°C, the proportion of mineral soil in $CaCO_3$ has to be subtracted in order to derive the amount of organic carbon (inorganic carbon is also oxidized). The pH value gives the first indication whether the sample has to be analyzed for inorganic carbon or not.

It is crucial to report in the metadata whether national SOC values refer to total C or if the inorganic component has been considered.

### Depth

The standard depth for GSOCmap is **0 cm to 30 cm** [@gsp_guidelines_2017]. Subdivisions are possible depending on the available data, by genetic horizons or depth classes. The following depths are additionally considered for GSOCmap (optional):

* **Forest floor**: Thickness (cm) subdivision in horizons depending on national soil inventory method (e.g. for forest floors organic layers L, F, H).

* **Peat**: From 30cm to 100cm, depending on national data.


## Soil depth estimate

### Completeness of depth estimate

Soil properties are commonly collected from field inventories (see Table \@ref(tab:horizon-level)) or from sampling and analyzing horizons and/or fixed depths. Since a fixed target depth of 30 cm is required for GSOC (other depth classes will be recommended in the future, following the [*GSP Guidelines for Sharing National Data/Information to Compile a Global Soil Organic Carbon (GSOC) Map*](http://www.fao.org/3/a-bp164e.pdf), data holders are confronted with the following options: 

* **Option 1**: Soil sampling has already considered this depth, data can be directly used for upscaling (see Chapter \@ref(mappingMethods)).
* **Option 2**: Horizons or layers/depth classes are sampled but aggregation is needed over the 0cm to 30cm.
* **Option 3**: The target depth (0cm to 30cm) was not completely covered by sampling, e.g. only the A horizon or a topsoil layer (e.g. 0cm to 20cm) has been sampled.

For both **Options 2** and **Option 3**, the transformation is needed, using e.g. equal-area splines. In the case of **Option 2**, the use of equal-area splines was first proposed by \cite{ponce1986improved}, and later tested against real data \citep{bishop1999modelling}. This technique is based on fitting continuous depth functions for modeling the variability of soil properties with depth. Thus, it is possible to convert soil profiles to standard depths, but also to fill gaps. The equal-area spline function consists of a series of local quadratic polynomials that join at so-called knots, located at the horizon boundaries, whereby the mean value of each horizon is maintained by the spline fit. They are called equal-area splines because the area to the left of the fitted spline curve is equal to the area to the right of the curve. 

```{r, fig.cap="An equal-area quadratic spline from Ponce-Hernandez et al. (1986) (Cited by Bishop et al., 1999)", out.width='80%', echo=FALSE, fig.align='center'}
knitr::include_graphics("images/spline.png")
```

In case of **Option 3**, additional information on the vertical distribution of carbon in the soils is required for accurate recalculation from the sampling depth to target depth, e.g. as was shown by \cite{bernoux1998modeling}.

### Technical steps - Equal-area splines using R {#EqualAreaSplines}

In **R** environment, the easiest way to apply equal-area splines is using the function `GSIF::mpspline` from the **R** package **GSIF** (\citep{hengl_2016_gsif}, see Section \@ref(SoilPedometrics)). For illustration, a sample dataset has been used (see Chapter \@ref(covariates)). This function requires data stored as `SoilProfileCollection` (SPC) using package **aqp**. Nevertheless, data in any local soil database or in tables like the ones proposed before (see Tables \@ref(tab:site-level), \@ref(tab:horizon-level)) can be transformed to an SPC.

The function `GSIF::mpspline` has several arguments. One of the arguments is the lambda value mentioned before. The proposed default value is 0.1. Another argument for this function is the target standard depths. The function produces spline-estimated values at these depths. However, this function also produces spline-estimated values at 1cm increments. 

The following technical steps require **R** and the named packages.

**Step 1 - Promote data table to SPC**

```{r, echo=T}
# Load aqp package
library(aqp)

# Promote to SoilProfileCollection 
# The SoilProfileCollection is a object class in R designed to 
# handle soil profiles
depths(dat) <- ProfID ~ top + bottom
```

**Step 2 - Add site-level data and coordinates**

```{r, echo=T}
# Merge the soil horizons information with the site-level 
# information from dat_sites
site(dat) <- dat_sites

# Set spatial coordinates
coordinates(dat) <- ~ X + Y

# A summary of our SoilProfileCollection
dat
```

**Step 3 - Run mass preserving splines for all the needed properties**

```{r splines, results='hide', message=FALSE, eval=TRUE}
library(GSIF)

# Estimate 0 cm - 30 cm standard horizons
# using mass preserving splines
try(SOC <- mpspline(dat, 'SOC', d = t(c(0,30))))
try(BLD <- mpspline(dat, 'BLD', d = t(c(0,30))))
try(CRFVOL <- mpspline(dat, 'CRF', d = t(c(0,30))))
```

**Step 4 - Convert back to table**

```{r, eval=TRUE}
# Prepare final data frame
dat <- data.frame(id = dat@site$ProfID,
                  Y = dat@sp@coords[,2],
                  X = dat@sp@coords[,1],
                  SOC = SOC$var.std[,1],
                  BLD = BLD$var.std[,1],
                  CRFVOL = CRFVOL$var.std[,1])

dat <- dat[complete.cases(dat),]

# Take a look at the results
head(dat)
```

**Step 5 - Estimate the soil organic carbon stock using the virtual horizons**

Finally, the estimation of the soil organic carbon stock (OCS) can be done using the **GSIF** package.

```{r estimation of OCS, eval=TRUE}
library(GSIF)

# Estimate organic carbon stock (OCS)
# SOC must be in g/kg
# BLD in kg/m3
# CRF in percentage %
OCSKGM <- OCSKGM(ORCDRC = dat$SOC, BLD = dat$BLD*1000, 
                 CRFVOL = dat$CRFVOL, HSIZE = 30)

dat$OCSKGM <- OCSKGM
dat$meaERROR <- attr(OCSKGM,"measurementError")
dat <- dat[dat$OCSKGM>0,]

summary(dat)
```

Soil organic carbon tends to have a log-normal distribution with a right-skew, and transforming the original values to its natural logarithm would generate a normal distribution of SOC values. Here we will test:

1. If the log-transformation of the response variable (SOC) tends to normality; and
2. If this transformation increases the simple correlation of SOC and its prediction factors. 

```{r, eval=TRUE, fig.cap='Statistical distribution of original values vs. log-transformed values for OCS '}
# Generate a new column with the transformed OCSKGM to its natural 
# logarithm
dat$OCSKGMlog <- log(dat$OCSKGM)

# Plot the next two plots as one
par(mfrow=c(1,2))
plot(density(dat$OCSKGM),
     main='Original values')

plot(density(dat$OCSKGMlog),
     main='Log-transformed values')
par(mfrow=c(1,1))

# We can save our processed data as a *.csv table
write.csv(dat, "data/dataproc.csv", row.names = FALSE)
```
