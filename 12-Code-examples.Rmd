# Code examples
*GF Olmedo*

## Data Preparation for Soil Profiles{#Data Preparation for Soil Profiles}

```{r data prep for soil profiles, eval=FALSE}
dat <- read.csv(file = "data/horizons.csv")

# Explore the data
str(dat)
summary(dat)

dat_sites <- read.csv(file = "data/site-level.csv")

# Explore the data
str(dat_sites)

# summary of column CRF (Coarse Fragments) in the example data base
summary(dat$CRF)

# Convert NA's to 0
dat$CRF[is.na(dat$CRF)] <- 0

hist(dat$CRF)

# Creating a function in R to estimate BLD using the SOC
# SOC is the soil organic carbon content in \%
estimateBD <- function(SOC, method="Saini1996"){
  OM <- SOC * 1.724
  if(method=="Saini1996"){BD <- 1.62 - 0.06 * OM}
  if(method=="Drew1973"){BD <- 1 / (0.6268 + 0.0361 * OM)}
  if(method=="Jeffrey1979"){BD <- 1.482 - 0.6786 * (log(OM))}
  if(method=="Grigal1989"){BD <- 0.669 + 0.941 * exp(1)^(-0.06 * OM)}
  if(method=="Adams1973"){BD <- 100 / (OM /0.244 + (100 - OM)/2.65)}
  if(method=="Honeyset_Ratkowsky1989"){BD <- 1/(0.564 + 0.0556 * OM)}
  return(BD)
}

# summary of BLD (bulk density) in the example data base
summary(dat$BLD)

# See the summary of values produced using the pedo-transfer 
# function with one of the proposed methods.
summary(estimateBD(dat$SOC[is.na(dat$BLD)], m
                   ethod="Honeyset_Ratkowsky1989"))

# Fill NA's using the pedotransfer function:
dat$BLD[is.na(dat$BLD)] <- estimateBD(dat$SOC[is.na(dat$BLD)], 
                                      method="Grigal1989")

# explore the results
boxplot(dat$BLD)

# Load aqp package
library(aqp)

# Promote to SoilProfileCollection 
# The SoilProfileCollection is a object class in R designed to 
# handle soil profiles
depths(dat) <- ProfID ~ top + bottom

# Merge the soil horizons information with the site-level 
# information from dat_sites
site(dat) <- dat_sites

# Set spatial coordinates
coordinates(dat) <- ~ X + Y

# A summary of our SoilProfileCollection
dat

library(GSIF)

## Estimate 0-30 standard horizon usin mass preserving splines
try(SOC <- mpspline(dat, 'SOC', d = t(c(0,30))))
try(BLD <- mpspline(dat, 'BLD', d = t(c(0,30))))
try(CRFVOL <- mpspline(dat, 'CRF', d = t(c(0,30))))

## Prepare final data frame
dat <- data.frame(id = dat@site$ProfID,
                  Y = dat@sp@coords[,2],
                  X = dat@sp@coords[,1],
                  SOC = SOC$var.std[,1],
                  BLD = BLD$var.std[,1],
                  CRFVOL = CRFVOL$var.std[,1])

dat <- dat[complete.cases(dat),]

## Take a look to the results
head(dat)

# Estimate Organic Carbon Stock
# SOC must be in g/kg
# BLD in kg/m3
# CRF in percentage
OCSKGM <- OCSKGM(ORCDRC = dat$SOC, BLD = dat$BLD*1000, 
                 CRFVOL = dat$CRFVOL, HSIZE = 30)

dat$OCSKGM <- OCSKGM
dat$meaERROR <- attr(OCSKGM,"measurementError")
dat <- dat[dat$OCSKGM>0,]
summary(dat)

## We can save our processed data as a table
write.csv(dat, "data/dataproc.csv")
```

## Data Preparation for Top Soil or Auger Samples {#Data Preparation for Top Soil or Auger Samples}  

```{r data prep for auger data, eval=FALSE}
dat <- read.csv(file = "data/auger.csv")

# Explore the data
str(dat)
summary(dat)

# Creating a function in R to estimate BLD using the SOC
# SOC is the soil organic carbon content in \%
estimateBD <- function(SOC, method="Saini1996"){
  OM <- SOC * 1.724
  if(method=="Saini1996"){BD <- 1.62 - 0.06 * OM}
  if(method=="Drew1973"){BD <- 1 / (0.6268 + 0.0361 * OM)}
  if(method=="Jeffrey1979"){BD <- 1.482 - 0.6786 * (log(OM))}
  if(method=="Grigal1989"){BD <- 0.669 + 0.941 * exp(1)^(-0.06 * OM)}
  if(method=="Adams1973"){BD <- 100 / (OM /0.244 + (100 - OM)/2.65)}
  if(method=="Honeyset_Ratkowsky1989"){BD <- 1/(0.564 + 0.0556 * OM)}
  return(BD)
}

# See the summary of values produced using the pedo-transfer 
# function with one of the proposed methods.
summary(estimateBD(dat$SOC, method="Honeyset_Ratkowsky1989"))

# Estimate BLD using the pedotransfer function:
dat$BLD <- estimateBD(dat$SOC, method="Grigal1989")

# explore the results
boxplot(dat$BLD)

# Remove points with NA's values
dat <- dat[complete.cases(dat),]

## Take a look to the results
head(dat)

# Estimate Organic Carbon Stock
# SOC must be in g/kg
# BLD in kg/m3
# CRF in percentage
OCSKGM <- OCSKGM(ORCDRC = dat$SOC, BLD = dat$BLD*1000, CRFVOL = 0, 
                 HSIZE = 30)

dat$OCSKGM <- OCSKGM
dat$meaERROR <- attr(OCSKGM,"measurementError")
dat <- dat[dat$OCSKGM>0,]
summary(dat)

## We can save our processed data as a table
write.csv(dat, "data/dataproc.csv")
```


## Mixing Covariates and Soil Points Data

```{r "join covariates and soil samples", eval=FALSE}
# Load the processed data. This table was prepared in the previous 
# chapter.
dat <- read.csv("data/dataproc.csv")

files <- list.files(path = "covs", pattern = "tif$", 
                    full.names = TRUE)

covs <- stack(files)

covs <- stack(covs, soilmap.r)

# correct the name for layer 14
names(covs)[14] <- "soilmap"

#mask the covariates with the country mask from the data repository
mask <- raster("data/mask.tif")

covs <- mask(x = covs, mask = mask)

plot(covs)

#upgrade points data frame to SpatialPointsDataFrame
coordinates(dat) <- ~ X + Y

# extract values from covariates to the soil points
dat <- extract(x = covs, y = dat, sp = TRUE)

# LCEE10 and soilmap are categorical variables
dat@data$LCEE10 <- as.factor(dat@data$LCEE10)
dat@data$soilmap <- as.factor(dat@data$soilmap)

#levels(soilmap) <- Symbol.levels

summary(dat@data)

dat <- as.data.frame(dat)

# The points with NA values has to be removed 
dat <- dat[complete.cases(dat),]

# export as a csv table
write.csv(dat, "data/MKD_RegMatrix.csv", row.names = FALSE)
```


## Fitting a RK model to predict the OCS

```{r "RK full example", eval=FALSE}
# load data
dat <- read.csv("data/MKD_RegMatrix.csv")

dat$LCEE10 <- as.factor(dat$LCEE10)
dat$soilmap <- as.factor(dat$soilmap)

# explore the data structure
str(dat)

library(sp)

# Promote to spatialPointsDataFrame
coordinates(dat) <- ~ X + Y

class(dat)

dat@proj4string <- CRS(projargs = "+init=epsg:4326")

dat@proj4string

library(raster)

# list all the itf files in the folder covs/
files <- list.files(path = "covs", pattern = "tif$", 
                    full.names = TRUE)

# load all the tif files in one rasterStack object
covs <- stack(files)

# load the vectorial version of the soil map
soilmap <- shapefile("MK_soilmap_simple.shp")

# rasterize using the Symbol layer
soilmap@data$Symbol <- as.factor(soilmap@data$Symbol)
soilmap.r <- rasterize(x = soilmap, y = covs[[1]], field = "Symbol")

# stack the soil map and the other covariates
covs <- stack(covs, soilmap.r)

# correct the name for layer 14
names(covs)[14] <- "soilmap"

# print the names of the 14 layers:
names(covs)

datdf <- dat@data

datdf <- datdf[, c("OCSKGM", names(covs))]

# Fit a multiple linear regression model between the log transformed
# values of OCS and the top 20 covariates
model.MLR <- lm(log(OCSKGM) ~ ., data = datdf) 

# stepwise variable selection
model.MLR.step <- step(model.MLR, direction="both")

# summary and anova of the new model using stepwise covariates 
# selection
summary(model.MLR.step)
anova(model.MLR.step)

# graphical diagnosis of the regression analysis
par(mfrow=c(2,2)) 
plot(model.MLR.step)
par(mfrow=c(1,1))

# collinearity test using variance inflation factors
library(car)
vif(model.MLR.step)

# problematic covariates should have sqrt(VIF) > 2
sqrt(vif(model.MLR.step))

# Removing B07CHE3 from the stepwise model:
model.MLR.step <- update(model.MLR.step, . ~ . - B07CHE3)

# Test the vif again:
sqrt(vif(model.MLR.step))

## summary  of the new model using stepwise covariates selection
summary(model.MLR.step)

# outlier test using the Bonferroni test
outlierTest(model.MLR.step)

# Project point data. 
dat <- spTransform(dat, CRS("+init=epsg:6204"))

# project covariates to VN-2000 UTM 48N
covs <- projectRaster(covs, crs = CRS("+init=epsg:6204"), 
                      method='ngb')

covs$LCEE10 <- as.factor(covs$LCEE10)
covs$soilmap <- as.factor(covs$soilmap)

# Promote covariates to spatial grid dataframe. Takes some time and 
# a lot of memory!
covs.sp <- as(covs, "SpatialGridDataFrame")
covs.sp$LCEE10 <- as.factor(covs.sp$LCEE10)
covs.sp$soilmap <- as.factor(covs.sp$soilmap)

# RK model 
library(automap)


# Run regression kriging prediction. This step can take hours...!
OCS.krige <- autoKrige(formula = 
                         as.formula(model.MLR.step$call$formula), 
                       input_data = dat, 
                       new_data = covs.sp,
                       verbose = TRUE,
                       block = c(1000, 1000))

OCS.krige

# Convert prediction and standard deviation to rasters
# And back-tansform the vlaues
RKprediction <- exp(raster(OCS.krige$krige_output[1]))
RKpredsd <- exp(raster(OCS.krige$krige_output[3]))


plot(RKprediction)

## Save results as tif files
writeRaster(RKprediction, filename = "results/MKD_OCSKGM_RK.tif", 
            overwrite = TRUE)

writeRaster(RKpredsd, filename = "results/MKD_OCSKGM_RKpredsd.tif", 
            overwrite = TRUE)

# save the model
saveRDS(model.MLR.step, file="results/RKmodel.Rds")
```

## Fitting a random forest model to predict the SOC

```{r, eval=FALSE}
library(reshape)

# Correlation analysis to select covariates
names(dat)
COR <- cor(as.matrix(dat[,7]), as.matrix(dat[,-c(1:8)]))
COR
x <- subset(melt(COR), value != 1 | value != NA)
x <- x[with(x, order(-abs(x$value))),]
x[1:25,]

idx <- as.character(x$X2[1:25])

dat2 <- dat[c('OCSKGM', idx)]
names(dat2)

COVall <- COV
COV <- COV[[idx]]

plot(COV)


library(randomForest)

# Try different values of mtry and select the model with the optimal 
# value
model <- tuneRF(dat[,c(names(COV))], dat$OCSKGM, stepFactor=1.5, 
                doBest = TRUE, improve = 0.5)
                       
# Use the model to predict the SOC in the covariates space
beginCluster()
start <- Sys.time()
pred <- clusterR(COV, predict, args=list(model))
print(Sys.time() - start)
endCluster()

```

## Fitting a svm model to predict the SOC

```{r, eval=FALSE}
# Correlation analysis to select covariates
names(dat)
COR <- cor(as.matrix(dat[,7]), as.matrix(dat[,-c(1:8)]))
COR
x <- subset(melt(COR), value != 1 | value != NA)
x <- x[with(x, order(-abs(x$value))),]
x[1:25,]

idx <- as.character(x$X2[1:25])

dat2 <- dat[c('OCSKGM', idx)]
names(dat2)

COVall <- COV
COV <- COV[[idx]]

plot(COV)


library(e1071)
library(caret)

#  Test different values of epsilon and cost
tuneResult <- tune(svm, OCSKGM ~.,  data = dat[,c("OCSKGM", 
                                                  names(COV))],
                   ranges = list(epsilon = seq(0,1,0.1), 
                                 cost = c(.5,1,1.5,2,5,10))
)

# Choose the model with the best combination of epsilon and cost
tunedModel <- tuneResult$best.model

# Use the model to predict the SOC in the covariates space
beginCluster()
start <- Sys.time()
pred <- clusterR(COV, predict, args=list(tunedModel))
print(Sys.time() - start)
endCluster()
```





`r if (knitr:::is_html_output()) '# References {-}'`
